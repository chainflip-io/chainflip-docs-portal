---

title: Maintenance

description: We use journald, which is systemd default log management service, to collect logs generated by the node and the engine.

---

import { Callout } from "nextra/components";

## Getting Logs

We use [`journald`](https://sagan.readthedocs.io/en/latest/journald.html), which is systemd default log management service, to collect logs generated by the node and the engine. To interact with it, you'll use `journalctl`. Below are some useful commands when debugging your validator node.

**Getting all logs for unit**

```bash copy
journalctl -u chainflip-node.service
```

This will output all logs generated by that unit. You hit `space` to scroll through the logs from older to newer.

**Following logs**

If you want to see logs in real time, run the following:

```bash copy
journalctl -f -u chainflip-node.service
```

### Using time ranges

To filter your logs using time ranges you can run the following:

**Relative time range**

```bash copy
journalctl -u chainflip-node.service --since "1 hour ago"
```

**Specific time ranges**

```bash copy
journalctl -u chainflip-node.service --since "2023-06-20 23:15:00" --until "2023-06-20 23:25:00"
```

### Setting Log Levels

Most of the time it is ok to just use the default log levels. However, these can be changed, either via environment variable, or dynamically.

**Environment Variable Log Level Changes**

The `RUST_LOG` environment variable controls the initial filtering directives if specified at engine startup.

For example:

```bash copy
export RUST_LOG="debug,warp=off,hyper=off,jsonrpc=off,web3=off,reqwest=off"
```

**Dynamic Log Level Changes**

Returns the current filtering directives:

```bash copy
curl -X GET 127.0.0.1:36079/tracing
```

> Note: The port used by the engine to accept these queries can be configured in your [`Settings.toml` file](/validators/mainnet/validator-setup#5-engine-settings).

Sets the filter directives so the default is DEBUG, and the logging in modules warp, hyper, jsonrpc, web3, and reqwest is turned off:

```bash copy
curl --json '"debug,warp=off,hyper=off,jsonrpc=off,web3=off,reqwest=off"' 127.0.0.1:36079/tracing
```

Equivalent to the above, but without using the --json short-hand:

```bash copy
curl -X POST -H 'Content-Type: application/json' -d '"debug,warp=off,hyper=off,jsonrpc=off,web3=off,reqwest=off"' 127.0.0.1:36079/tracing
```

The syntax for specifying filtering directives is given [here](https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html).


## Migrating to a Different Server

One of your amazing community members has developed this guide. After you have created a new machine and finished all the steps up to and including [Creating new linux users](/validators/mainnet/validator-setup#creating-new-linux-user), follow this guide.

<Callout type="warning">
    Do *not* perform migration steps during a rotation.
</Callout>

### Backup Your Engine Database from the Old Server

The engine database contains the threshold signing keyshares of your validator. Thus, you should backup this database before you start the migration process, and ensure you keep it stored safely and securely.

`/etc/chainflip/data.db` is the default location. If you have changed the location, please adjust the path accordingly. The path the engine uses for it's database is specified in the [Engine Settings](/validators/mainnet/validator-setup#5-engine-settings) section.

```toml
# Optional
# [signing]
# db_file = "/etc/chainflip/data.db"
```

```bash copy
# Run these commands on your old server
sudo systemctl stop chainflip-engine

cp /etc/chainflip/data.db /etc/chainflip/data.db.backup
# Restart the engine on your old server while setting up the new one
sudo systemctl start chainflip-engine
```

### Backup your Authorship Keys

/etc/chainflip/chaindata/chains/Chainflip-Perseverance/keystore


### Transfer Database Backup to Your New Server

You'll need to transfer the database backup from your old server to the new one. Use the `scp` command from your new server to securely copy the file:

```bash copy
# Run these commands on your new server
mkdir -p /etc/chainflip/

# Run this command on your new server
# Replace OLD_SERVER_IP with your old server's IP address
# Replace username with your username on the old server
scp username@OLD_SERVER_IP:/etc/chainflip/data.db.backup /etc/chainflip/

# Rename the file to data.db
mv /etc/chainflip/data.db.backup /etc/chainflip/data.db
```

<Callout type="info">
    You may need to use `sudo` to place the file in the destination directory and/or create the directory, or alternatively copy it to your home directory first and then move it with sudo.
</Callout>


### On Your New Machine

**Download Binaries via APT Repo**

```bash copy
gpg --keyserver hkp://keyserver.ubuntu.com --recv-keys BDBC3CF58F623694CD9E3F5CFB3E88547C6B47C6
```

**Verify the key's authenticity**

```bash copy
gpg --export BDBC3CF58F623694CD9E3F5CFB3E88547C6B47C6 | gpg --show-keys
```

<Callout type="warning">
    **Important:** Make sure you see the following output from the terminal:

    ```
    pub   rsa3072/0xFB3E88547C6B47C6 2022-11-08 [SC]
    Key fingerprint = BDBC 3CF5 8F62 3694 CD9E  3F5C FB3E 8854 7C6B 47C6
    uid                              Chainflip Labs GmbH <dev@chainflip.io>
    sub   rsa3072/0x48249A1599E31935 2022-11-08 [E]
    ```

</Callout>

**Add Chainflip's Repo to apt sources list**

```bash copy
gpg --export BDBC3CF58F623694CD9E3F5CFB3E88547C6B47C6 | sudo tee /etc/apt/trusted.gpg.d/chainflip-perseverance.gpg
echo "deb [arch=amd64 signed-by=/etc/apt/trusted.gpg.d/chainflip-perseverance.gpg] https://repo.chainflip.io/perseverance/jammy jammy main" | sudo tee /etc/apt/sources.list.d/chainflip.list
```

**Installing The Packages**

```bash copy
sudo apt-get update
sudo apt-get install -y chainflip-cli chainflip-node chainflip-engine
```

**Create the keys directory**

```bash copy
sudo mkdir /etc/chainflip/keys
```

<Callout type="info">
    **Note:** After this you don't need to generate new Signing Keys, you can skip
    that phase and continue to the command below with your **old** Seed Secret.
</Callout>

### Recovering Your Keys

`THE_OLD_PHRASE` \<< change to your old phrase you have backed up.

```bash copy
chainflip-cli generate-keys \
    --path /etc/chainflip/keys \
    --seed-phrase 'THE_OLD_PHRASE'
```

<Callout type="info">
    Please note that the `Node Key` cannot be recovered, a new one will be generated. This will result in a new peer id for your node.
</Callout>

### Transfer your Authorship Keys

The Authorship keys are not restored from the seed, they need to be copied from the old machine.

By default, your block authorship keys are stored under `/etc/chainflip/chaindata/chains/Chainflip-Perseverance/keystore`.

If your node is a current authority, failing to copy these to the new node will prevent it from authoring blocks (and earning rewards).

```bash copy
scp -r username@OLD_SERVER_IP:/etc/chainflip/chaindata/chains/Chainflip-Perseverance/keystore /etc/chainflip/chaindata/chains/Chainflip-Perseverance/keystore
```

### Back Them Up & Copy Your Validator ID

```bash copy
sudo chmod 600 /etc/chainflip/keys/ethereum_key_file
sudo chmod 600 /etc/chainflip/keys/signing_key_file
sudo chmod 600 /etc/chainflip/keys/node_key_file
history -c
```

<Callout type="warning">
    Make sure to update your config file with the IP address of the new VPS.
    Otherwise you'll get slashed once you start the engine on the new VPS.
</Callout>

<Callout type="warning">
    **Do not run two instances of your Validator at the same time**. You will
    almost certainly be slashed. Make sure you turn off your old server before you
    turn on your new one.
</Callout>

### Stop the old server and start the new one

After that make sure to stop the engine and the node on the old VPS by running:

**On the **<span style={{ color: "red"}}>**Old**</span>** VPS**

```bash copy
sudo systemctl disable --now chainflip-node.service
sudo systemctl disable --now chainflip-engine.service
sudo apt purge chainflip-node
sudo apt purge chainflip-engine
```

**On the **<span style={{ color: "green"}}>**New**</span>** VPS**

1. Setup the config file as explained in [Engine Settings](/validators/mainnet/validator-setup#5-engine-settings) section.
2. Then start the node and engine services as explained in [Start up](/validators/mainnet/validator-setup#starting-the-node) section.
